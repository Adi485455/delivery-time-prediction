{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14264981,"sourceType":"datasetVersion","datasetId":9102783}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-16T08:09:04.575419Z","iopub.execute_input":"2026-01-16T08:09:04.575727Z","iopub.status.idle":"2026-01-16T08:09:04.587280Z","shell.execute_reply.started":"2026-01-16T08:09:04.575700Z","shell.execute_reply":"2026-01-16T08:09:04.586241Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/data-with-features-csv/Deeper Regression Features (1).csv\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T08:09:04.794216Z","iopub.execute_input":"2026-01-16T08:09:04.794989Z","iopub.status.idle":"2026-01-16T08:09:04.799418Z","shell.execute_reply.started":"2026-01-16T08:09:04.794957Z","shell.execute_reply":"2026-01-16T08:09:04.798277Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T08:09:04.963985Z","iopub.execute_input":"2026-01-16T08:09:04.964744Z","iopub.status.idle":"2026-01-16T08:09:04.968656Z","shell.execute_reply.started":"2026-01-16T08:09:04.964708Z","shell.execute_reply":"2026-01-16T08:09:04.967917Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"file_path=\"/kaggle/input/data-with-features-csv/Deeper Regression Features (1).csv\"\npd_read=pd.read_csv(file_path)\nprint(f\"Dataset_shape{pd_read.shape}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T08:09:05.128916Z","iopub.execute_input":"2026-01-16T08:09:05.130143Z","iopub.status.idle":"2026-01-16T08:09:05.138365Z","shell.execute_reply.started":"2026-01-16T08:09:05.130109Z","shell.execute_reply":"2026-01-16T08:09:05.137256Z"}},"outputs":[{"name":"stdout","text":"Dataset_shape(100, 4)\n\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"rows_to_display=15\nprint(pd_read.head(rows_to_display))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T08:09:07.103975Z","iopub.execute_input":"2026-01-16T08:09:07.104822Z","iopub.status.idle":"2026-01-16T08:09:07.112775Z","shell.execute_reply.started":"2026-01-16T08:09:07.104789Z","shell.execute_reply":"2026-01-16T08:09:07.111786Z"}},"outputs":[{"name":"stdout","text":"    distance_miles  time_of_day_hours  is_weekend  delivery_time_minutes\n0             1.60               8.20           0                   7.22\n1            13.09              16.80           1                  32.41\n2             6.97               8.02           1                  17.47\n3            10.66              16.07           0                  37.17\n4            18.24              13.47           0                  38.36\n5             5.74              16.59           0                  29.06\n6             8.80              12.25           0                  23.94\n7            15.36              11.76           1                  32.40\n8             5.35               9.42           0                  17.06\n9             2.46              14.44           0                  14.09\n10            6.51               8.00           0                  33.38\n11            4.06               9.33           1                  17.38\n12           18.66              14.86           1                  36.75\n13           16.35              19.09           0                  38.86\n14           13.03              13.42           0                  32.55\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"import seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T08:09:07.268786Z","iopub.execute_input":"2026-01-16T08:09:07.269692Z","iopub.status.idle":"2026-01-16T08:09:07.273667Z","shell.execute_reply.started":"2026-01-16T08:09:07.269654Z","shell.execute_reply":"2026-01-16T08:09:07.272706Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"sample_tensor=torch.tensor([\n     # distance, time_of_day, is_weekend, delivery_time\n    [1.60,      8.20,        0,          7.22],   # row 1\n    [13.09,     16.80,       1,          32.41],  # row 2       \n    [6.97,      8.02,        1,          17.47],  # row 3\n    [10.66,     16.07,       0,          37.17],  # row 4\n    [18.24,     13.47,       0,          38.36]   # row 5\n],dtype=torch.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T08:09:07.624056Z","iopub.execute_input":"2026-01-16T08:09:07.624534Z","iopub.status.idle":"2026-01-16T08:09:07.629917Z","shell.execute_reply.started":"2026-01-16T08:09:07.624502Z","shell.execute_reply":"2026-01-16T08:09:07.629022Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"sample_hours=sample_tensor[:,1]\nsample_weekends=sample_tensor[:,2]\n\nprint(f\"Sample hours: {sample_hours}\")\nprint(f\"Sample Weekends: {sample_weekends}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T08:09:10.843752Z","iopub.execute_input":"2026-01-16T08:09:10.844707Z","iopub.status.idle":"2026-01-16T08:09:10.852482Z","shell.execute_reply.started":"2026-01-16T08:09:10.844661Z","shell.execute_reply":"2026-01-16T08:09:10.851522Z"}},"outputs":[{"name":"stdout","text":"Sample hours: tensor([ 8.2000, 16.8000,  8.0200, 16.0700, 13.4700])\nSample Weekends: tensor([0., 1., 1., 0., 0.])\n","output_type":"stream"}],"execution_count":69},{"cell_type":"markdown","source":"**# **As there are the two shifts in the weekdays we can there is late probably due to the high traffic so we need to make that different time slots so first we test the function on the limited time slot testing on the above time slots****","metadata":{}},{"cell_type":"code","source":"def rush_hours_features(hours_tensor,weekends_tensor):\n    ## Morning rush is in between 8 to 10\n    ## And Evening rush is in between 16 to 19\n    ## Here we cant use the basic python functionalities like \"if\" can't use and the chaining of the boolen symbols can use\n    is_morning_rush=(8.0>=hours_tensor) & (hours_tensor<10)\n    is_evening_rush=(16.0>=hours_tensor) & (hours_tensor<19)\n    is_weekday=(weekends_tensor==0)\n    is_rush_hour_mask=is_weekday & (is_evening_rush | is_morning_rush)\n    return is_rush_hour_mask.float()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T08:09:13.780474Z","iopub.execute_input":"2026-01-16T08:09:13.781332Z","iopub.status.idle":"2026-01-16T08:09:13.786187Z","shell.execute_reply.started":"2026-01-16T08:09:13.781298Z","shell.execute_reply":"2026-01-16T08:09:13.785196Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"rush_hour_sample=rush_hours_features(sample_hours,sample_weekends)\n\nprint(f\"Sample Hour: {sample_hours.numpy()}\")\nprint(f\"Sample Weekday: {sample_weekends.numpy()}\")\nprint(f\"Rush_hour_on_sample: {rush_hour_sample.numpy()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T08:09:14.234023Z","iopub.execute_input":"2026-01-16T08:09:14.234365Z","iopub.status.idle":"2026-01-16T08:09:14.240880Z","shell.execute_reply.started":"2026-01-16T08:09:14.234335Z","shell.execute_reply":"2026-01-16T08:09:14.240092Z"}},"outputs":[{"name":"stdout","text":"Sample Hour: [ 8.2  16.8   8.02 16.07 13.47]\nSample Weekday: [0. 1. 1. 0. 0.]\nRush_hour_on_sample: [1. 0. 0. 0. 1.]\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"def prepare_data(df):\n    # Extarcting all the data from the dataframe in the numpy array formate\n    all_values=df.values\n    \n    # Converting all the data into the single tensor\n    full_tensor=torch.tensor(all_values,dtype=torch.float32)\n    \n    # Now To feed the data to the NN we need them in the numerical foramate so need to convert features in the raw data formate (slicing them)\n    raw_distance=full_tensor[:,0]\n    raw_hours=full_tensor[:,1]\n    raw_weekends=full_tensor[:,2]\n    raw_targets=full_tensor[:,3]\n    \n    # We need to call the rush hour function to engineer new fetures of the RUSH HOURS\n    is_rush_hour_feature=rush_hours_features(raw_hours,raw_weekends)\n    \n    # Unsqueeze(1) all the features to add them a new dimention 1D -> 2D\n    #.unsqueeze(1)-> means add the new dimension of the 1 \n    distances_col=raw_distance.unsqueeze(1)\n    hours_col=raw_hours.unsqueeze(1)\n    weekends_col=raw_weekends.unsqueeze(1)\n    rush_hour_col=is_rush_hour_feature.unsqueeze(1)\n    \n    # Normalize the all the values\n     # First find the mean and std values\n    dist_mean,dist_std=distances_col.mean(),distances_col.std()\n    hours_mean,hours_std=hours_col.mean(),hours_col.std()\n    \n     # Now Find the Normalize values\n    dist_norm=(distances_col-dist_mean)/dist_std\n    hours_norm=(hours_col-hours_mean)/hours_std\n    \n    # Now Concatinate all the features into the single tensor\n    prepared_features=torch.cat([\n        dist_norm,\n        hours_norm,\n        weekends_col,\n        rush_hour_col\n    ],dim=1)\n    \n    # Dimention 1 ensure that all must concatinated into the column wise features side-by-side \n    prepared_target=raw_targets.unsqueeze(1)\n    result_dict={\n        'full tensor':full_tensor,\n        'raw distance':raw_distance,\n        'raw hours':raw_hours,\n        'raw weekends':raw_weekends,\n        'raw targets':raw_targets,\n        'distances col':distances_col,\n        'hours col':hours_col,\n        'weekends col':weekends_col,\n        'rush hour col':rush_hour_col\n    }\n    norm_stats = {\n        \"dist_mean\": dist_mean,\n        \"dist_std\": dist_std,\n        \"hours_mean\": hours_mean,\n        \"hours_std\": hours_std\n    }\n\n\n    return prepared_features,prepared_target,norm_stats\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T08:15:27.307359Z","iopub.execute_input":"2026-01-16T08:15:27.308350Z","iopub.status.idle":"2026-01-16T08:15:27.316278Z","shell.execute_reply.started":"2026-01-16T08:15:27.308314Z","shell.execute_reply":"2026-01-16T08:15:27.315504Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"# Process the entire DataFrame to get the final feature and target tensors.\nfeature, target,norm_stats = prepare_data(pd_read)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T08:15:27.548715Z","iopub.execute_input":"2026-01-16T08:15:27.549715Z","iopub.status.idle":"2026-01-16T08:15:27.555391Z","shell.execute_reply.started":"2026-01-16T08:15:27.549678Z","shell.execute_reply":"2026-01-16T08:15:27.554551Z"}},"outputs":[],"execution_count":84},{"cell_type":"markdown","source":"**Defining the Architecture of the Model**","metadata":{}},{"cell_type":"code","source":"def init_model():\n    # Defining the Random seed To ensure the random input\n    torch.manual_seed(42)\n    \n    # Defining the Model\n    model=nn.Sequential(\n        nn.Linear(4,64),\n        nn.ReLU(),\n        nn.Linear(64,32),\n        nn.ReLU(),\n        # Output Function\n        nn.Linear(32,1)\n    )\n    optimizer=torch.optim.SGD(model.parameters(),lr=0.01)\n    loss_function=nn.MSELoss()\n    \n    return model,optimizer,loss_function\n    \n \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T08:15:28.123523Z","iopub.execute_input":"2026-01-16T08:15:28.124241Z","iopub.status.idle":"2026-01-16T08:15:28.129372Z","shell.execute_reply.started":"2026-01-16T08:15:28.124208Z","shell.execute_reply":"2026-01-16T08:15:28.128589Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"model, optimizer, loss_function = init_model()\n\nprint(f\"{'='*30}\\nInitialized Model Architecture\\n{'='*30}\\n{model}\")\nprint(f\"{'='*30}\\n Optimizers Optim \\n{'='*30}\\n{optimizer}\")\nprint(f\"{'='*30}\\n Loss Function \\n{'='*30}\\n {loss_function}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T08:15:30.484583Z","iopub.execute_input":"2026-01-16T08:15:30.484933Z","iopub.status.idle":"2026-01-16T08:15:30.493338Z","shell.execute_reply.started":"2026-01-16T08:15:30.484905Z","shell.execute_reply":"2026-01-16T08:15:30.492510Z"}},"outputs":[{"name":"stdout","text":"==============================\nInitialized Model Architecture\n==============================\nSequential(\n  (0): Linear(in_features=4, out_features=64, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=64, out_features=32, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=32, out_features=1, bias=True)\n)\n==============================\n Optimizers Optim \n==============================\nSGD (\nParameter Group 0\n    dampening: 0\n    differentiable: False\n    foreach: None\n    fused: None\n    lr: 0.01\n    maximize: False\n    momentum: 0\n    nesterov: False\n    weight_decay: 0\n)\n==============================\n Loss Function \n==============================\n MSELoss()\n","output_type":"stream"}],"execution_count":86},{"cell_type":"markdown","source":"*****Now Training the Model Inside the loop with the epoches*****","metadata":{}},{"cell_type":"code","source":"def train_model(features,targets,epochs,verbose=True):\n    # First of all we need to intialize the list to store the losses\n    # Here below We are gonna calculating the losses then we gonna store them inside this one list\n    losses=[]\n\n\n\n    # Now we gonna call the funtion init_model to use its features or simply we are gonna initialized\n    # the model,optimizer,loss_funtion w.r.t init_model() function\n    \n    model,optimizer,loss_funtion=init_model()\n\n    for epoch in range(epochs):\n        # Now call the Forward pass means just passing the features through the model\n\n        # Here the features mens the exactly the prepared_features from the earlier means the normalized values of the hours and all\n        outputs=model(features)\n\n        # Calculating the loss from the loss function\n        loss=loss_function(outputs,targets)\n\n        # Setting the Optimizers to the zero Grad means giving it the reboot\n        optimizer.zero_grad()\n\n        # Settig up the backward Function to calculate the updated values of the weights and the biases (Strictly it does not update the values Updating takes place at the optimizers step)\n        loss.backward()\n\n        # Now the Updating the Weights and the biases in the optimizer Step\n        optimizer.step()\n\n        if (epoch+1)%5000==0:\n            losses.append(loss.item())\n            if verbose:\n                print(f\"Epoch[{epoch+1}/{epochs}],Loss:{loss.item():.4f}\")\n    return model,losses\n\n        \n       \n\n    \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T08:15:31.020974Z","iopub.execute_input":"2026-01-16T08:15:31.021940Z","iopub.status.idle":"2026-01-16T08:15:31.028185Z","shell.execute_reply.started":"2026-01-16T08:15:31.021892Z","shell.execute_reply":"2026-01-16T08:15:31.027310Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"test_model=train_model(feature,target,10000)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T08:20:24.469633Z","iopub.execute_input":"2026-01-16T08:20:24.470505Z","iopub.status.idle":"2026-01-16T08:20:31.997289Z","shell.execute_reply.started":"2026-01-16T08:20:24.470469Z","shell.execute_reply":"2026-01-16T08:20:31.996553Z"}},"outputs":[{"name":"stdout","text":"Epoch[5000/10000],Loss:5.2706\nEpoch[10000/10000],Loss:1.6766\n","output_type":"stream"}],"execution_count":96},{"cell_type":"code","source":"trained_model,losses=train_model(feature,target,30000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T08:20:31.998772Z","iopub.execute_input":"2026-01-16T08:20:31.999111Z","iopub.status.idle":"2026-01-16T08:20:54.251100Z","shell.execute_reply.started":"2026-01-16T08:20:31.999084Z","shell.execute_reply":"2026-01-16T08:20:54.250148Z"}},"outputs":[{"name":"stdout","text":"Epoch[5000/30000],Loss:5.2706\nEpoch[10000/30000],Loss:1.6766\nEpoch[15000/30000],Loss:1.5119\nEpoch[20000/30000],Loss:0.7385\nEpoch[25000/30000],Loss:0.3740\nEpoch[30000/30000],Loss:0.4246\n","output_type":"stream"}],"execution_count":97},{"cell_type":"markdown","source":"**Now Then Making the predication of the values****","metadata":{}},{"cell_type":"code","source":"def prepare_single_input(distance, hours, is_weekend, norm_stats):\n    # Compute rush hour feature\n    rush_hour = rush_hours_features(\n        torch.tensor([hours]),\n        torch.tensor([is_weekend])\n    ).item()\n\n    # Normalize using TRAINING stats\n    dist_norm = (distance - norm_stats[\"dist_mean\"]) / norm_stats[\"dist_std\"]\n    hours_norm = (hours - norm_stats[\"hours_mean\"]) / norm_stats[\"hours_std\"]\n\n    # Final 2D tensor (1 sample, 4 features)\n    input_tensor = torch.tensor(\n        [[dist_norm, hours_norm, is_weekend, rush_hour]],\n        dtype=torch.float32\n    )\n\n    return input_tensor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T08:21:01.939754Z","iopub.execute_input":"2026-01-16T08:21:01.940142Z","iopub.status.idle":"2026-01-16T08:21:01.946370Z","shell.execute_reply.started":"2026-01-16T08:21:01.940112Z","shell.execute_reply":"2026-01-16T08:21:01.945288Z"}},"outputs":[],"execution_count":98},{"cell_type":"code","source":"distance_miles = 15\ntime_of_day_hours = 14\nis_weekend = 0\n\ninput_tensor = prepare_single_input(\n    distance_miles,\n    time_of_day_hours,\n    is_weekend,\n    norm_stats\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T08:21:04.078921Z","iopub.execute_input":"2026-01-16T08:21:04.080147Z","iopub.status.idle":"2026-01-16T08:21:04.085704Z","shell.execute_reply.started":"2026-01-16T08:21:04.080098Z","shell.execute_reply":"2026-01-16T08:21:04.084718Z"}},"outputs":[],"execution_count":99},{"cell_type":"code","source":"with torch.no_grad():\n    predicted_time = trained_model(input_tensor).item()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T08:21:04.469064Z","iopub.execute_input":"2026-01-16T08:21:04.469669Z","iopub.status.idle":"2026-01-16T08:21:04.475233Z","shell.execute_reply.started":"2026-01-16T08:21:04.469628Z","shell.execute_reply":"2026-01-16T08:21:04.474426Z"}},"outputs":[],"execution_count":100},{"cell_type":"code","source":"print_prediction_result(\n    distance=distance_miles,\n    time_str=\"14:00\",\n    is_rush_hour=False,\n    predicted_time=predicted_time\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-16T08:21:04.918798Z","iopub.execute_input":"2026-01-16T08:21:04.919170Z","iopub.status.idle":"2026-01-16T08:21:04.924370Z","shell.execute_reply.started":"2026-01-16T08:21:04.919144Z","shell.execute_reply":"2026-01-16T08:21:04.923335Z"}},"outputs":[{"name":"stdout","text":"\n+------------------------------------------+-----------------------+\n|                         Model Prediction                         |\n+------------------------------------------+-----------------------+\n| Time of the Week                         | Weekday               |\n| Distance                                 | 15.0 miles          |\n| Time                                     | 14:00                 |\n| Is this considered a rush hour period?   | No                    |\n+------------------------------------------+-----------------------+\n| Estimated Delivery Time                  | 39.45 minutes    |\n+------------------------------------------+-----------------------+\n\n","output_type":"stream"}],"execution_count":101},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}